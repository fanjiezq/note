https://zhuanlan.zhihu.com/p/79219960
https://tech.meituan.com/2016/06/24/java-hashmap.html
# HashMap
## 实现原理
+ HashMap 简单来说就是一个链表数组，基础是一个数组，每个数组元素是一个链表(Entry)
+ 元素存储时会先对key进行hash计算，然后对数组length取模，确认元素应该保存在数组的哪个位置，如果该位置已经被占用，则比较key值，不相同就保存在当前元素后面，形成链表
    - 在比较链表元素时，先比较hash值，值不同则两者一定不是同一个元素，值相同再调用equal进行比较，这也是为什么我们在重写对象equal方法以后必须重写hash方法
    - 所有类的 equal() 和 hash() 都继承自 Object 类，默认情况下其equal() 和 hash() 是等价的，都是比较两个对象的内存地址.我们重写 equal() 目的就是为了修改这种直接比较内存地址的语义，但是如果不重写hash()就会导致两个对象 equal() 一样 hash() 不一样，在使用Map类容器时，插入两个equal()相等的key时，我们本意是这两个key相等，但是比较时hash()必然不等，所以会出现问题。
+ 当某个链表的数量大于8时，链表会进行结构调整，如果数组长度 <64,会先进行扩容，因为简单的扩容可能就可以使数据分布比较均匀；如果数组长度 >= 64 ,链表会转为红黑树，提升查找效率

## 扩容机制
+ HashMap有两个核心参数，数组大小(length)和负载因子(loadFactor)。数组大小不必说默认16，负载因子是为了控制数据的密集程度，默认0.75
+ 当HashMap存储的Node数量 > (length * loadFactor),数组容量会扩展到原来的两倍，扩容的目的是为了减少hash碰撞，碰撞越多，链表就越长，查询插入和查询效率越低
    - 1.7:新建一个2倍大小的新数组，然后将旧数组的数据经过重新计算迁移到新数组中，插入采用头插法，在单线程下没有问题，但是多线程情况下，链表可能导致死循环
    - 1.8:新建一个2倍大小的新数组，然后按照数组的桶位一个桶位一个桶位的迁移。迁移方式不是重新计算数据的位置，而是判断链表中key的hash值的二进制，将链表拆分为高位链表个低位链表，低位链直接存储到扩展的数组的对应位置(老表的位置+老表size)。而且插入方式改为尾插法

## 线程安全问题
+ HashMap的resize过程在多线程并发调用时，可能出现死循环
+ HashMap的put方法并没有锁机制，如果A，B两个线程同时put数据，A在hash计算完成后恰好时间片用完，B此时正常插入数据，等到A再次运行时不会在重新Hash而是直接插入数据，就会导致A覆盖了B的数据
+ 迭代器的快速失败问题，当HashMap使用迭代器遍历时，另一个线程添加或者删除了元素，迭代器会立即抛出异常

# ConcurrentHashMap
https://pdai.tech/md/java/thread/java-thread-x-juc-collection-ConcurrentHashMap.html
## jdk7实现
+ 底层依旧是链表数组的形式，但是在最外层加了Segment概念，每个 Segment 管理一个链表数组，在数据插入和查询要经过两次hash,先找到所在的segment,然后定位存储在数组的位置。可以看做N个HashMap组合成了一个大的HashMap
+ Segment 的数量是可以配置的，但是一定是2的指数倍，Segment 在对象创建的时候确定，默认为16，一旦确定无法再修改，避免修改引起整体rehash,所以很自然的ConcurrentHashMap在扩容时也是单个segment进行扩容的
+ 针对put操作，使用局部加锁的方式保证数据安全和高性能。Segment 继承了ReentrantLock，所以它本身就是一个锁，所以在进行数据存储时，会对Segment加锁，只要数据分布在不同的Segment，数据存储完全的隔离，不会出现竞争的情况，所以Segment 的数量也决定了最高并发度。线程获取锁时首先尝试使用自旋锁，自旋一定次数后转为阻塞锁
+ 针对get操作，使用 volatile 变量保证变量可见性，保证get操作时之前所有对变量的修改都可见
+ 针对遍历操作，ConcurrentHashMap 支持在遍历过程中修改容器数据，且修改对后续遍历可见

## JDK8 实现
+ jdk7的分段锁实现使 ConcurrentHashMap 理论上最大并发度为 Segment 个数，但是其寻址多了一次hash操作，JDK8 抛弃了 Segment 概念，其底层数据结构又变回 HashMap 一样，只有一个链表数组，不同的是在进行数据存储时，如果链表已经存在元素，就对链表的第一个元素使用 synchronized 加锁，也可以保证线程安全，且实现更简单
+ get方法是没有加锁的，所以在数据插入过程中可以并发读取数据，在get过程中，链表node的value是volatile修饰的，保证变量的可见性

## jdk1.8扩容机制
+ 内部维护一个CtrlSize变量标识当前HashMap的状态
    - CtrlSize == -1 :表示当前HashMap正在初始化
    - CtrlSize <= 0 and CtrlSize != -1 : 表示当前HashMap正处于扩容状态，且反映出参与扩容的线程数量
    - CtrlSize > 0: 表示触发扩容的阈值
+ 当一个线程触发扩容后，他会先更新CtrlSize的值，然后新建一个2倍的数组，数据也是按照数组桶迁移，每个桶最多由一个线程负责，将链表拆分为高位链表个低位链表，低位链直接存储到扩展的数组的对应位置
+ 在扩容过程中可以读数据，每个桶都有一个迁移成功标识，在迁移完成之前，在旧表中查询，迁移完成后到新表查询
+ 如果迁移过程中有线程要进行写操作，如果当前桶还没迁移，那线程就在旧表上正常写就可以了;如果对应的桶正在扩容，那当前线程会参加到扩容线程组中帮助扩容。因为无论是写数据还是扩容，都需要获取到对应桶的链表头节点的锁，所以是线程安全的
