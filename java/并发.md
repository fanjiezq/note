# java内存模型
+ java为了屏蔽硬件之间的内存差异,自己定义了一个内存模型,保证java程序在任何平台都可以稳定的运行
+ java的内存模型是建立在jvm虚拟机上的,所以java内存模型中的内存,概念上属于jvm虚拟机申请的物理内存的子集
+ java内存模型将内存分为两部分,主内存和工作内存,主内存属于公共内存,被线程共享,工作内存是线程私有内存
+ java线程只会操作工作内存的数据,如果数据保存在主内存,也会先将数据从主内存加载到工作内存,操作完成后再写回到主内存

# 多线程提升性能原理
+ 并发编程很多情况下可以提升程序性能，但这不是绝对的，通常在IO密集型应用中并发可以发挥很大作用，但是CPU密集型应用却不可以，根本原因在于并发编程的最终目的是尽力压榨计算机硬件资源，让所有硬件都尽量出于忙碌状态，此处的硬件绝大多数时间是指CPU和IO设备，所以并发编程就是CPU和IO合作过程
+ CPU运行的每一条指令都属于一个线程，程序在进行cpu运算时如果需要磁盘数据，必须等到数据加载完成才能继续运算，此时线程就是阻塞状态。阻塞状态的线程线程无事可做，为了不白白浪费CPU资源，操作系统会将这个线程存放到阻塞队列，调度其他线程使用CPU，但是此时IO设备其实在为阻塞的线程加载数据，这就让IO设备和CPU同时工作。所以在IO密集型应用中，可以保持CPU和IO设备的高效利用
+ 需要注意的是，线程状态的切换是有成本的，操作系统必须保存线程挂起时的上下文，阻塞线程运行时又要恢复上下文，所以线程不是越多越好，过多的线程可能造成系统假死，看起来CPU在工作，但是实际上并没有进行计算，而是在不断进行线程切换。

# 多线程问题
+ 缓存导致的数据不一致：多线程最常见的问题是数据安全问题，即多个线程修改一个共享变量，变量的最终结果不符合程序预期值。引起线程安全问题的根本原因是java内存模型设计，JMM内存模型规定，静态变量，成员变量等数据必须保存在主内存，而变量的修改必须在工作内存中进行，这就导致一个线程修改一个成员变量必须经过三步，1）从主存加载数据到工作内存 2）修改数据 3）将数据从工作内存刷新到主存。这三个步骤不是原子的，于是在多个线程同时修改同一个变量时，就会出现数据不符合预期的情况。
+ 指令重排导致的变量不可见：jvm为了程序性能，在编译时可能会进行指令重排，两个修改操作之间不存在依赖关系，指令重排后不影响最终结果，那么最终编译出来的指令顺序和代码的顺序就可能不一致。在但线程情况下不会出现问题，但是多线程情况就可能出现问题。假设A,B两个线程共享X，Y两个变量。假设A先修改了X,后修改了Y,但是线程B在读取数据时可能发现Y更新了但是X没更新的情况。很多情况下可能出现很奇怪的逻辑问题。为解决指令重排引起的问题，java引入happen-before机制
	- Happens-Before原则:对于两个操作A,B,如果规则规定A happen-before B,无论AB两者是不是运行在同一线程，jvm保证在操作B执行时，A的一切修改都是可见的
	- 锁定规则:解锁之前的所有操作 happen-before 于加锁之后而所有操作。此规则保证了在获取锁时，之前线程对临界区域的所有修改都是可见的
	- volatile变量规则:对一个volatile变量的写操作以及写操作之前的所有操作 happen-before 于读操作。此规则保证了在读取volatile变量时，之前线程对volatile变量的更新都是可见的，而且对volatile变量的读写操作可以看作一个代码屏障，屏障之前和屏障之后的代码绝对不会进行指令重排


# 保证线程安全的手段
## volatile 型变量
+ volatile变量是最轻量级的线程同步手段,它有两个特点
    - 线程对volatile变量的修改,其他线程都能看到
    - volatile变量可以防止指令重排序,避免因为编译器优化导致的逻辑错误,最常用于 双重锁检测
+ volatile 变量修改可以被所有线程感知的实现原理是,线程每次使用volatile变量,都会从主内存获取,每次修改完成后也会第一时间写回主内存
+ volatile 变量的修改虽然可以被其他线程感知,但是它并不能保证多线程情况下的数据安全，因为volatile变量的修改也不是原子操作，在多个线程修改时一样会发生更新丢失问题,volatile变量只适合一写多读的情况

## 使用原子类
+ 出现线程安全很大比例都是更新丢失问题,即一个线程正在更新一个变量(比如自增)时另一个线程同时也更新了这个变量,本来是两次更新,但是结果却只是一次更新的效果
+ 出现更新丢失问题的核心在于更新操作这个动作对线程来说并非原子操作,如果保证更新操作是原子的,即线程更新过程中是不可被打断的,即便是被打断本次更新也会被回滚,就能保证不出现更新丢失,java提供了原子变量类专门用于解决此类问题
+ 原子变量类的实现原理是CAS(compare and swap),线程调用一个cas(x,y,z) 指令，x代表要修改的变量，y代表变量的旧的预期值，z代表x要更新的数据。在指令执行时只有 x = y,才允许 x值被设为z，cas依赖了cpu提供的一些原子化指令
+ CAS 可以保证操作的原子性，而且不会出现线程阻塞， 成本很底，但是不适合并发量非常大的场景，并发量很大会导致cas操作经常失败，cas会不断重试，导致程序进入假死状态

## ThreadLocal
+ ThreadLocal 好像线程的本地变量，每个线程可以有一份变量的拷贝，线程的数据独立，使用起来互补干扰，有些情况可以避免使用原子类或者锁机制
+ ThreadLocal 变量实现原理是一个ThreadLocal对象内部维护了一个 ThreadMap，Thread为key，变量值为value,每个线程使用时都会以自己为key获取到自己的value
+ ThreadLocal 变量存在内存泄漏的风险，当一个线程执行完成后被回收，此线程在ThreadLocal内部的对应的value就永远无法再被清除，所以在使用时必须在线程被销毁前清理掉线程对应数据 

## 加锁
+ 原子类能解决丢失更新的问题,但它只适合变量修改, 适用场景十分有限.许多复杂业务需要使用锁来解决竞争条件保证数据安全
+ 锁是解决多线程安全的最常用手段,java有很多类型的锁,最常用的是synchronized关键字创建的锁.锁类型和实现差别很大,基本原理是一致的,就是线程执行到临界区域时需要首先获取到一个锁对象才可以进入临界区域,锁对象一旦被一个线程获取必须等到释放后其他线程释放才可以获取,以此保证同一时间只有一个线程可以进入临界区域执行代码


# 锁
锁的种类很多，用于适应各种业务场景，主流锁包含以下几种，是从不同角度在概念上进行分类，在实际实现上存在重合
## 锁分类
+ 悲观锁VS乐观锁
	- 原理：悲观锁和乐观锁体现了线程看待数据安全的态度，悲观锁是线程假设自己在操作数过程中一定就有其他线程修改数据，所以先锁住数据；乐观锁是线程假设自己操作过程中没有其他线程修改数据，所以不会锁住数据，当提交修改时检查数据的正确性，如果数据被修改了再进行回滚重试(自旋)
	- 实现：Synchronize 和 ReentrantLock 类都是悲观锁，原子类的自增操作使用的CAS操作是乐观锁。
	- 适用场景：悲观锁适合写多读少的场景，保证每次写都正确；乐观锁适合读多写少，写过多会导致写操作总是(自旋)
+ 阻塞锁VS自旋锁
	- 原理：线程切换要经过线程保存上下文，加入阻塞队列，恢复上下文，这一步骤成本很高，如果临界代码很简单，线程切换时间可能比代码执行时间还长，得不偿失。这种情况下如果遇到竞争的时候，线程不进行切换，而是等待一小段时间可能更好。锁导致等待线程进入阻塞队列就是阻塞所。锁导致线程不切换而是等待一段时间再就是自旋锁
	- 实现：Synchronize 和 ReentrantLock 类都是阻塞锁，原子类的自增操作使用的CAS操作是自旋锁
	- 适用场景：悲观锁适合临界代码执行时间长的程序，自旋锁适合临界代码执行时间短的程序，因为自旋会使用CPU，长时间的自旋会一直占用cpu资源
+ 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁
	- 原理：这四种锁其实是描述锁的四种状态，且仅仅针对 Synchronize 锁。Synchronize 是悲观锁且是阻塞锁，它拥有这两者的缺点，其早期的实现就是简单利用操作系统的锁，非常重，所以在很多场景下很低效。为了优化Synchronize锁性能，java调整其底层实现，将锁分级
	- 实现：1) 使用 Synchronize 修饰的代码段岁开始是无锁状态，任何线程可以并行读取数据但是不能修改 2) 一旦有一个线程修改了数据，锁升级为偏向锁，偏向锁适用于哪些只有一个线程修改数据的场景，锁会保有此线程的id，线程退出临界状态不会释放锁，下次进入也不需要重新获取锁 3) 在偏向锁状态下，如果有另一个线程竞争锁，就升级为轻量级锁，此线程通过自旋的方式获取锁，不会阻塞 4）如果锁被一个线程持有，还有一个线程在自旋等待，此时第三个线程竞争锁，轻量级锁升级为重量级锁 
+ 公平锁VS非公平锁
	- 原理：锁存在一个等待队列，竞争环境下没有获取到锁的线程都会进入队列等待。公平锁就是线程按照申请顺序进入队列，后来线程直接进入队尾排队；非公平锁是后来线程先尝试插队获取锁，没有获取到再进入队尾排队。非公平锁在一些场景下比公平锁性能更高，因为某些携程可能直接获取到锁，少了一次线程切换时间
	- 实现：Synchronize 是非公平锁， ReentrantLock 实现了公平锁和非公平锁
	- 适用场景：公平锁在实现和管理方面更可控，不会出现线程饥饿；非公平锁在临界代码执行时间短的情况下更有优势，因为这种情景存在大量线程切换，公平锁可能节省很多线程切换
+ 共享锁 VS 排他锁
	- 原理：共享锁和排他锁是一种概念，共享锁就是多个线程可以持有同一个锁，但是都只能读数据，排他锁就是锁同一时间只能被一个线程持有，持有线程可以读写数据，其他线程不可以读写数据。这两个锁一般配合适用
	- 实现：ReentrantReadWriteLock 
	- 适用场景：ReentrantReadWriteLock  适用读操作远大于写操作的场景，可以保证读数据的高效性也能保证写数据的数据安全
+ 可重入锁VS不可重入锁
	- 原理：可重入锁指线程获取锁以后在临界代码中可以再次获取锁，反之就是不可重入锁，可重入锁可以避免死锁
	- 实现：Synchronize 和 ReentrantLock 都是可重入锁，NonReentrantLock 是不可重入锁

## wait 和 notify
+ Object 方法提供了 wait() 和 notify() 用于线程之间的协作，当线程A获取到对象锁后调用wait() 方法就会进入wait状态，并释放掉锁，等待线程B获取到锁并调用notify() 唤醒自己
+ wait/notify 机制的底层实现依赖监视器模式，java将对象封装成为一个监视器对象MonitorObject,其含有三个重要属性，
	- owner:持有当前监视器对象的线程
	- waitSet:监视器对象上等待状态的线程集合
	- BlockSet:监视器对象上阻塞状态的线程集合
+ 调用 wait() java会将当前线程加入到监视器对象等待队列，等待队列的线程不会再被调度。调用notify()方法后java会将等待队列的线程移动到阻塞队列，线程可以重新开始进行调度，重新争夺锁运行

## Synchronized
+ Synchronized 是java提供的语法级别锁，它有两个作用，一是保证修改的可见性，即一个线程在Synchronized代码块中修改变量，其他线程都可见；二是保证指令的顺序，防止指令重排序
+ Synchronized 的实现依赖对象监视器，每个对象都是一个对象监视器，加锁就是获取这个对象监视器的所有权，当代码执行到 Synchronized 时会尝试获取锁对象的所有权，只有获取到才可以执行代码。对象监视器的关键在对象的对象头部分，对象头包含一个Mark Word记录了对象的元数据信息，其中就有对象持有者的指针和一些锁的级别信息。更底层的锁是依赖硬件提供一些互斥元语实现
+ 对于线程的管理，与wait/notify 底层机制一样

## ReentrantReadWriteLock
+ ReentrantReadWriteLock 底层是依赖 AQS 实现，AQS提供了一个管理线程的框架，它由一个状态，一个等待队列，以及一套线程阻塞和唤醒机制组成，依赖这一套框架可以不依赖java的对象监视器实现锁机制
+ AQS 维护一个volatile变量state代表锁状态，state = 0 代表没有线程占用锁，state = 1 代表有线程占用锁。其内部还维护了一个阻塞队列，用于保存被阻塞的线程，队列是一个FIFO的双向链表
+ 获取锁流程:线程A,B,C同时抢占锁，首先检查 state 是否为0 ，为0则代表锁没有被占用，线程尝试以cas的方式将state更新为1,并且将owner变量设置为自己。如果A修改变量成功，则A获取到锁，B,C被加入阻塞队列，加入队列的流程也是以cas的方式，确定各自在链表中的位置
+ 释放锁流程:线程A执行完任务后尝试释放锁，有三个步骤 1）将state设置为0 2）将owner变量设置为null 3）将阻塞队列链表的第一个线程唤醒
+ 非公平锁实现VS公平锁实现: 公平与非公平锁体现在锁被释放时新来的线程如何处理，如果新来的线程直接参与锁竞争，那么队列中被唤醒的线程就可能再次被阻塞，被插队，这就是非公平的；新来的进程先看一下阻塞队列是否为空，如果非空就直接加入到队列末尾不参与锁竞争，这个就是公平的


# 常用线程安全类
## 同步容器类(使用了synchronized)
+ Vector
+ HashTable
+ ConcurrentHashMap:线程安全的map,用于替代HashTable,使用分段锁保证线程安全,减小了锁的粒度,提升了并发性
+ CopyOnWriteArrayList:List的线程安全版本,用于替代Vector,使用写时复制保证线程安全.即在线程对容器进行修改时,java会自动拷贝一份数据,所有的修改都在此数据上面，写完以后将原对象引用指向拷贝的容器。但是写数据依旧加锁，否则可能拷贝出多个副本。但是比起 Vector 性能依旧高很多，因为 Vector 每个方法都加锁
+ CopyOnWriteArraySet:Set的安全版本,写时复制技术
+ ConcurrentQueue
+ ConcurrentDequeue
+ ConcurrentSkipListSet

# 线程间的通信方式
+ volatile 实现的信号量，应用于flag 
+ wait/notify机制
+ CyclicBarrier:循环栅栏，用于一组线程等到一定状态后一起执行
+ CountDownLatch:用于在程序的某个点阻塞，等到一定数量的线程执行完以后再继续执行。常用于父线程等待多个子线程运行完
+ Semaphore: 像一种锁池，用于控制同一时间只有固定数量的线程可以执行


# 线程池
## 线程池的几大属性
1. 核心线程
2. 最大线程
3. 非核心线程空闲存活时间
4. 任务队列
5. 线程工厂
6. 拒绝策略
## 线程池的常用任务队列
1. 直接提交(SynchronousQueue)，队列本身不保存任务，只是传递一个消息。CachedThreadPool 使用这种队列实现，因为它是无界的线程池，每来一个任务就新建一个线程，没有必要保存任务。可以设置为公平还是非公平的
2. 无界队列(LinkedBlockingQueue)
3. 有界队列(ArrayBlockingQueue)
## 线程池的四种拒绝策略
1. 拒绝:AbortPolicy
2. 丢弃新来的任务:DiscardPolicy
3. 丢弃最老的任务:DiscardOldestPolicy
4. 调用者执行:CallerRunsPolicy
## 线程池类型以及使用场景
1. SingleThreadExecutor:只有一个线程的线程池，主要用于保证同一时间只有一个线程在运行，控制任务执行顺序
2. FixedThreadPool:固定数量的线程池，主要为了限制线程数量，控制服务器的资源使用
3. CachedThreadPool: 无界线程池，常用于执行很多短期的异步任务
4. ThreadPoolExecutor: 动态线程池，分为核心线程和最大线程，具有多种线程阻塞队列和拒绝策略


# 线程状态: new | runnable | running | blocked | terminated
# 线程用到模板方法设计模式，run() 负责定义行为， start() 负责启动线程，并且执行 run()
# thread和runable用到策略模式，Thread负责线程本身相关的职责和控制，Runnable负责执行逻辑单元
# 每个 thread 实例被创建时只是一个实例，并没有被转换为操作系统的一个线程；每个thread都是另一个线程创建的，也就是它的父线程，Java都是由main方法启动，main线程是所有线程的祖先线程
