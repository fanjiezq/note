# 基本使用

    public class MyKafkaConsumer implements Runnable{

        private String groupId;

        public MyKafkaConsumer(String groupId) {
            this.groupId = groupId;
        }

        @Override
        public void run() {

            KafkaConsumer<String, String> kafkaConsumer = null;
            try {
                Properties kafkaProps = new Properties();
                kafkaProps.put("bootstrap.servers", "127.0.0.1:9092");
                kafkaProps.put("group.id", groupId);
                kafkaProps.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
                kafkaProps.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
                kafkaConsumer = new KafkaConsumer<>(kafkaProps);

                //指定消费者消费的分区
                //List<TopicPartition> topicPartitions = Arrays.asList(new TopicPartition("topic_twopartition", 1));
                //kafkaConsumer.assign(topicPartitions);

                kafkaConsumer.subscribe(Arrays.asList("topic_twopartition"));
                while (true){
                    //从服务器获取消息,在指定的时间返回
                    //注意这个需要一直存在, 因为它不只是为了获取消息,也是服务端的心跳,如果不轮循,服务器会认为次消费者死亡
                    //因为心跳的原因,消费者的处理逻辑必须简单而快读
                    ConsumerRecords<String, String> poll = kafkaConsumer.poll(Duration.ofMillis(100));

                    Iterator<ConsumerRecord<String, String>> iterator = poll.iterator();

                    while (iterator.hasNext()){
                        ConsumerRecord<String, String> next = iterator.next();
                        System.out.println("key:" + next.key() + " value:" + next.value() + " pattition:"+ next.partition() + " offset:" + next.offset());
                    }

                }

            } catch (Exception e){
                e.printStackTrace();
            }
            finally {
                kafkaConsumer.close();
            }
        }
        
    }

## 消费者退出
调用 consumer.wakeup() 可以退出 poll(),且此方法可以在其他线程安全调用

## 线程安全
消费者是线程不安全的,所以不应该让多个线程共享一个消费者

## 消费者配置
https://kafka.apache.org/documentation/#consumerconfigs

## 偏移量的记录方式和偏移量的更新
偏移量被记录在kafka的一个特殊的主题_consumer_offset下,记录格式为 (Group id + 主题 + 分区号) : offset.可见偏移量是针对分区和消费者组的,每个消费者组对应的每个分区的偏移量是独立的
偏移量的更新是消费者的操作,更新策略包括主动提交和手动提交
+ 自动提交:设置 enable.auto.commit=true,消费者会自动把从 poll() 方法接收到的最大偏移量提交上去,默认5秒,使用auto.commit.interval.ms设置时间间隔,自动提交是在轮询里进行的,消费者每次在进行轮询时会检查是否该提交偏移量了,达到时间就提交.自动提交比较简单,且因为是批量提交,性能较高.缺点是如果消费者宕机,最新的偏移量没来得及更新,服务器进行再均衡后,这部分消息会被重新消费
+ 手动提交:设置 enable.auto.commit=false使用  kafkaConsumer.commitSync() 手动提交,只要没有发生不可恢复的错误， commitSync() 方法会一直尝试直至提交成功.手动提交的好处就是安全,坏处是在 broker 对提交请求作出回应之前，应用程序会一直阻塞,吞吐量会有一定程度的降低. 为了提升性能也可以使用 kafkaConsumer.commitAsync() 异步提交,异步的好处是提高提同吞吐量.缺点是可能因为网络波动出现提交顺序不一致,如果程序正常不会有什么问题,如果此时消费者宕机,那么之前提交的偏移量失效,再均衡以后这部分消息会被重新消费


## 再均衡监听器
无论使用哪种策略提交偏移量,如果程序发生意外的再均衡,都有可能的导致数据安全,比如使用最安全的同步方式提交偏移量,当一个消费者拉取了一百条消息,但是只处理了五十条,服务器发生再均衡,此时必须将五十条的偏移量提交上去,也只能提交五十条,这样当前分区被重新绑定的消费者才可能准确的继续进行消费
所以单纯的依靠kafka提供的接口无法做到保证消息的绝对不会被重复消费,要保证这一点有两种方式,一是让消息的消费和偏移量的提交作为一个事务,具有原子性;二是将消息的偏移量保存在本地,每次启动和再均衡时先从本地读取上次的偏移量
Kafka提供了再均衡监听器供我们在系统发生再均衡时做一些特殊的处理,只要实现ConsumerRebalanceListener接口,并将实现传递给消费者

## 消费模式
+ 至少一次:有的系统需要消息最少一次,容忍重复,不容忍丢失.kafka偏移量量自动提交策略就可以满足这种系统
+ 最多一次:有的系统需要消息最多一次,容忍丢失,不容忍重复.kafka无法保证这种系统,可以使用第三方的软件,比如数据库的主键,来保证数据的唯一性
+ 仅一次:有的系统要求消息消费一次且仅有一次.kafka的提交策略可以保证不丢失.不容忍重复可以使用第三方软件解决
