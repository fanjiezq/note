# 环境搭建
## 单机模式搭建
1. 搭建java环境.设置环境变量JAVA_HOME
2. 搭建zookeeper
3. 修改broker.id,broker.id,zookeeper.connect
4. 解压kafak压缩包,使用 ./kafka-server-start.sh -daemon ../config/server.properties 启动
5. 配置操作系统的 vm.swappiness=1,非必要情况下不使用交换空间,提升系统吞吐量,重启kafka

## 集群搭建
1. 搭建zookeeper集群
2. 修改 broker.id=1;zookeeper.connect
3. 使用./kafka-server-start.sh -daemon ../config/server.properties 启动所有节点

## 常规配置
+ brokeer.id: 每个 broker 都需要有一个标识符，在整个 Kafka 集群里必须是唯一的
+ port: kafka端口,默认9092
+ zookeeper.connect: zk地址
+ log.dirs: 消息存储位置
+ num.recovery.threads.per.data.dir: 服务器启动打开分区日志片段,崩溃重启后检查分区日志,都需要后台线程处理,对于包含大量分区的服务器来说,适当多的线程可以提升性能.(需要注意的是这里的线程数量是针对一个log.dirs的,如果有两个log.dirs实际线程数量会乘以2)
+ auto.create.topics.enable :此配置打开,当生产者生产第一条消息,或者消费者消费第一条消息,都会自动创建主题
+ log.retention.ms: 消息的保留时间,默认168小时
+ log.retention.bytes:每个分区最大保留的字节数
+ log.segment.bytes:每个日志片段最大字节数,每个分区都是由多个日志片段构成
+ log.segment.ms:日志片段关闭时间
+ message.max.bytes :单个消息大小

## 常用命令
+ 启动
./kafka-server-start.sh -daemon ../config/server.properties
+ 创建主题:
./kafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 2 --topic topic1
+ 查询所有主题:
./kafka-topics.sh  --zookeeper node1:2181 --list
+ 查看一个主题的具体信息
./kafka-topics.sh  --zookeeper 127.0.0.1:2181 --describe --topic test
+ 用console向主题发布消息
./kafka-console-producer.sh --broker-list node1:9092 --topic test
+ 用console从kafka读取消息
./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test 


# 基本概念
## 生产者
生产消息的程序,一般为端设备产生的日志,流水等数据
## 消费者
处理消息的程序
## 主题
消费的一种属性,kafak数据以消息的形式存在,每个消息都属于一个主题,生产者可以根据消息的特点将消息发送到不同的主题下,消费者可以根据需要订阅不同的主题,主题的存在使得消息可以根据特性区分开来
## 分区
+ 主题是一类数据的集合,它可以被分成更小的集合,就是分区.一个主题由一个或者多个分区组成.分区即是一直逻辑概念,也是一种物理概念,每个分区在磁盘上体现为一个文件夹,分区是kafka逻辑上的最小单位
## 分片
分片是分区的子集,每个分区由一个或者多个分片组成,分片是数据存储的真正位置,是kafka物理上的最小单位,但是它对于生产者和消费者是不可见的,了解分片主要是为了更好的理解kafka管理数据的方式
## 消费者组
+ 每个消费者都属于一个消费者组.每个组可以有一个或者多个消费者
+ 每个消费者组只能消费一个主题下的消息.且消息由组中的消费者共同消费,每个消息只会被组中的一个成员消费
+ 多个组可以消费同一个主题下的消息,每个组之间互不干扰
## 消息偏移量
+ 消息偏移量是记录消费者消费消息的进度, 用于记录消息是否已经被消费,偏移量被保存在kafka的一个特殊主题上,消费者可以随时获取偏移量,避免消息丢失和重复消费
## 分区再均衡
+ 消费者消费消息时会和固定分区绑定,就是说一个分区的消息总是被一个消费者消费.
+ 当消费者数量少于分区数量,每个消费者会消费多个分区的消息;两者数量相等时,每个分区对应一个消费者;当消费者数量多于分区数量,一部分消费者会闲置
+ 当添加或者删除,消费者,分区和消费者会重新绑定,被称为再均衡,这种均衡是自动的,但是尽量避免,因为再均衡期间,这个消费者组无法获取消息

# 生产者使用
## 基本使用 

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        Properties kafkaProps = new Properties();
        kafkaProps.put("bootstrap.servers", "127.0.0.1:9092");
        kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(kafkaProps);

        Future<RecordMetadata> send = kafkaProducer.send(new ProducerRecord<>("topic","value"));
        kafkaProducer.send(new ProducerRecord<>("topic", "key", "value"), new Callback() {
            @Override
            public void onCompletion(RecordMetadata recordMetadata, Exception e) {

            }
        });

    }

## 序列化器
生产者发送的消息必须被序列化,所以需要一个序列化器,kafka有自己默认的序列化器,但是也可以使用三方序列化框架,必须protobuf,avro,还可以实现自定义的序列化器

## 消息key值
消息可以是key:value形式的.也可以是只有一个value的形式.key的存在是value的附加值,可以用以区分数据,相同的key会被服务器放在同一个分区.单纯的value,就相当与key=null,消息会被随机的分发到任意分区

## 分区器
除了依据key值让服务器自动分区,我们还可以制定分区器,根据key值进行自定义分区

## 错误处理
生产者发送消息到队列可能出现错误,错误大体上分为可重试解决的错误和不可通过重试解决的错误,前者可能是服务器进行再均衡,或者网络波动,后者可能性很多,我们需要根据业务定制异常处理策略,是否重试,重试多少次,如果不能通过重试解决,需要怎么办