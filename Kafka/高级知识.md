# kafka高效的原因
+ 线性的磁盘写:生产者的消息都是追加到磁盘的,属于线性磁盘写,速度非常高
+ 批量数据读取:消费者消费消息是一次性获取一个数据集,批量读取数据,所以系统吞吐量非常高,而且数据包比较大,网络传输消息也很高
+ 零拷贝:一般情况下一个在磁盘上的数据传递到网络中需要经历如下四个步骤,涉及到两次系统调用和四次数据拷贝,零拷贝技术允许操作系统直接把pagecache发送到network,只有一次数据拷贝
    1. The operating system reads data from the disk into pagecache in kernel space
    2. The application reads the data from kernel space into a user-space buffer
    3. The application writes the data back into kernel space into a socket buffer
    4. The operating system copies the data from the socket buffer to the NIC buffer where it is sent over the network
+ 异步刷盘:kafka写入的数据并不是每个消息到来后直接写入磁盘,而是存储到文件系统,存储到文件系统后数据实际存储在pagecache,由操作系统来判断什么时候写入磁盘,kafka也提供强制刷盘的参数来强制执行刷盘的系统调用,但是建议不使用这些参数,其认为数据的可靠性通过replica来保证，而强制flush数据到磁盘会对整体性能产生影响。

# 日志清理策略
kafka的日志清理有两种策略,delete和compact，从使用log.cleanup.policy 参数配置,默认是delete.delete就是根据配置的消息保留的时间和分区大小,达到条件的消息被自动删除,compact是进行消息压缩,后台线程定时清理,根据消息的key,相同的key只保留最后一个值,在一些特定场景可以使用.也可以两个策略都配置

# 消息的存储
+ kafka的每个主题可能有多个分区,每个分区体现在磁盘上就是一个目录,每个分区又被分为多个分片保存,默认每个分片1G,每个分片的命名是这个分片第一条消息在本分区的偏移量
+ 分片中保存着一条条消息,消息包含消息头和消息体,头部包含了消息的长度和消息的唯一id,此唯一id是kafka自动生成,实际上就是消息的偏移量
+ 除了日志文件,还存在一个索引文件,用于加速定位消息的具体位置

# 消息的可靠性保证
## 服务器
1. 复制系数 replication.factor: 创建主题时需要指定主题的复制系数N.主题的每个分区数据都会被保留N个副本,那么在 N-1 个副本失效的情况下系统仍然可用
2. 最少同步副本 min.insync.replicas: kafka可以在主题和broker级别上设置最小同步的副本,生产者在提交消息时,必须有指定数量的副本同步以后才算提交成功,如果集群只有一个节点,但是最少同步副本设置未2,消息永远提交不可能成功.

## 生产者
1. 消息回执request.required.acks:生产者发送消息需要收到服务器的ack才可以算是提交成功,acks可以配置为0,1,all,0代表不接受ack,1代表首领节点同步成功即可,all代表所有节点同步成功,为了保证数据不丢失,可以配置为all
2. 可靠的异常处理:即便服务器已经万无一失,消息依旧可能丢失,比如复制系数=3,最少同步副本=3,消息acks=all,如果在生产者发送消息时,分区的首领刚好崩溃，新的首领正在选举当中， Kafka 会向生产者返回“首领不可用”的响应.如果生产有处理这个错误,消息就会丢失.

## 消费者
1. 偏移量的自动提交和手动提交:enable.auto.commit可以设置消息偏移量的提交方式是自动还是手动,自动提交比较简单,且因为是批量提交,性能较高.缺点是如果消费者宕机,最新的偏移量没来得及更新,服务器进行再均衡后,这部分消息会被重新消费.使用  kafkaConsumer.commitSync() 手动提交,只要没有发生不可恢复的错误， commitSync() 方法会一直尝试直至提交成功.手动提交的好处就是安全,坏处是在 broker 对提交请求作出回应之前，应用程序会一直阻塞,吞吐量会有一定程度的降低. 为了提升性能也可以使用 kafkaConsumer.commitAsync() 异步提交,异步的好处是提高提同吞吐量.缺点是可能因为网络波动出现提交顺序不一致,如果程序正常不会有什么问题,如果此时消费者宕机,那么之前提交的偏移量失效,再均衡以后这部分消息会被重新消费.
2. 保证数据处理完成提交偏移量:消费者都是批量拉取消息的,且为了保证心跳不过期,数据一般是异步处理,如果偏移量在消息处理完成前就提交,消费者消息处理了一半宕机,消息就会丢失,所以需要保证偏移量在消息处理完成后再提交,如果必须提前提交偏移量,也需要保留和记录消息,保证丢失的消息可以恢复
3. 再均衡监听器:无论使用哪种策略提交偏移量,如果程序发生意外的再均衡,都有可能的导致数据安全,比如使用最安全的同步方式提交偏移量,当一个消费者拉取了一百条消息,但是只处理了五十条,服务器发生再均衡,此时必须将五十条的偏移量提交上去,也只能提交五十条,这样当前分区被重新绑定的消费者才可能准确的继续进行消费,所以单纯的依靠kafka提供的接口无法做到保证消息的绝对不会被重复消费,要保证这一点有两种方式,一是让消息的消费和偏移量的提交作为一个事务,具有原子性;二是将消息的偏移量保存在本地,每次启动和再均衡时先从本地读取上次的偏移量


# 消息传输保障
消息传输保障描述消息从生产者到消费者的情况,有的系统允许消息重复不允许丢失,有的允许丢失不允许重复,更严格的是要求消息消费且仅仅被消费一次.这种保障需要生产者, 服务器和消费者三方合作完成
+ 最少一次:即保证消息不丢失,可重复
    - 服务器保证:消息只要被提交到服务器,到因为副本的存在, 消息就不会丢失
    - 生产者保证:生产者保证只有收到ack才算是消息提交了,如果遇到网络问题,生产者还会自动进行重试
    - 消费者保证:消费者每次批量拉取消息后,必须保证消息被处理过了,然后才提交偏移量
+ 最多一次:即保证消息不重复,可丢失
    - 服务器保证:无需参与
    - 生产者保证:设置ack=0,只负责发消息,不管消息是否提交成功,这样消息就不会重复
    - 消费者保证:拉取消息后直接提交偏移量,异步处理消息,不处理异常消息,消息不会重复
+ 仅一次:在 最少一次 保证消息不重复消费
    - 服务器保证:消息只要被提交到服务器,到因为副本的存在, 消息就不会丢失
    - 生产者保证:生产者保证只有收到ack才算是消息提交了,如果遇到网络问题,生产者还会自动进行重试
    - 消费者保证:消费者每次批量拉取消息后,必须保证消息被处理过了,然后才提交偏移量,保证消息不丢失;然后利用三方系统(比如数据库主键)保证消息只会被处理一次,去除重复消息.

# 消息的顺序
每个kafka的主题可能有多个分区,kafka保证每个分区内消息的顺序,并不保证主题内消息的整体顺序

# 消息过期
kafka可以配置消息的过期策略,log.retention.ms和log.retention.bytes两个配置项分别配置消息过期时间和最大的保留数量,达到其中任意一个条件,消息就会被删除.需要注意的是,消息的删除是基于日志片段的,也就是删除动作会删除整个日志片段,如果日志过期时间是一天,但是一个日志片段保存了五天的数据,消息实际上会被保留五天

# 垃圾回收和