# 基本术语
+ 机器学习的数据集合称为数据集 (data set)
+ 每条数据为一个示例或样本 （instance）
+ 示例结果信息被称为标记（label）
+ 拥有标记的示例被称为样例（example）
+ 反映事物在某方面表现或者性质称为属性(attribute) 或者特征 (featue);
+ 属性张成的空间被称为属性空间 （attribute space）或样本空间（sample space）例如判断西瓜是否熟了，把西瓜的大小，颜色，敲击声响作为三个坐标张成一个描述西瓜的三维空间，每个西瓜都会落在这个空间的一个坐标，每个坐标点都称为一个特征向量（feature vector）
+ 学得模型对应的关于数据的某种潜在规律称为假设（hypothesis），潜在规律自身称为真实，学习目的就是为了逼近真实。
+ 假设是潜在规律，潜在规律无从把我，机器学习的过程就是在所有可能的假设中进行搜索，找到一个最匹配训练集的假设，这是一个归纳过程，称为归纳学习(inductive learning)
+ 好的假设可以很好的匹配训练集，甚至训练集之外的数据集，但假设并非真理，它可能存在或不存在，可能唯一或不唯一，在训练过程中可能找到了多个假设都能很好的匹配当前训练集，那么学习过程就产生了一个假设集合，我们称之版本空间(version space)
+ 版本空间会产生一个问题，可能多个假设对数据集的整体匹配正确率一致，但是对单个用例匹配结果不一致，模型必须对版本空间的假设进行偏好选择， 称为归纳偏好(inductive bias)
+ 预测值是离散值，例如好瓜，坏瓜，此类学习任务被称为分类（classification）；若预测值为连续值，如西瓜的成熟度为0.75、0.97，此类学习任务被称为回归(regression)
+ 学得模型后对其进行预测的过程称为测试，被预测的样本称为测试样本
+ 还可以对样本进行聚类(clustering), 即将训练集的数据分为若干组，每组称为一个簇（cluster）
+ 根据训练数据是否拥有标记信息，学习任务可以分为监督学习(supervised learning)和无监督学习(unsupervised learning)，分类和回归属于前者，聚类属于后者
+ 学得模型适应新样本的能力称为泛化能力(generalization)

# 机器学习模型训练步骤
1. 获取数据
2. 数据基本处理
3. 特征工程: 把数据集变为对机器更友好的数据
    + 特征提取
        - 基于信息熵和信息增益选择合适的特征
    + 特征预处理
        - 归一化
        - 标准化
    + 特征降维(去除冗余的，重复的特征)
        - Filter
            - 方差选择法: 过滤低方差特征，方差低说明这个特征所有样本都差不多
            - 相关系数(皮尔森相关系数、PCA降维度): 过滤掉特征之间相关性很强的特征，相关性很强说明特征重复或者冗余了
        - Embeded
            - 决策树
            - 正则化
            - 深度学习
4. 机器学习算法模型训练
    + 机器学习的实质就是从在输入空间和输出空间之间找到一个映射关系，这个映射关系可以很好的匹配和预测输入空间和输出空间，这个映射关系的具体体现就是模型
        - 输入空间: 输入的特征的全集
        - 输出空间: 输出的特征全集
        - 假设空间: 输入空间和输出空间的映射关系的全集， 这个映射关系可能非常多，机器学习的目的就是找到一个能最好的表示两者映射关系的集作为最终的模型输出
5. 模型评估
6. 应用
# 机器学习算法分类
+ 监督学习: 数据集包含特征值和目标值
    - 分类问题: 目标值是离散的
        - K-近邻算法
            - 算法的核心就是以邻居的类型判断我的类型，我的类型就是距离我最近的K个邻居的类型
            - 判断两个数据的距离可以选择欧式距离法或者曼哈顿距离等；K 的取值需要根据训练出的模型进行评估
        - 贝叶斯分类
        - 决策树与随机森林
        - 逻辑回归
    - 回归问题: 目标值是连续的
        - 线性回归、岭回归
+ 无监督学习: 数据集只包含特征值，不包含目标值
    - 聚类k-means