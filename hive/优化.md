# 配置优化
## 简单查询不启动MR任务
+ hive本身存在部分优化，比如简单的查询不需要开启MR任务，直接读取数据过滤即可，hive提供配置项hive.fetch.task.conversion=none|minimal|more实现此功能
    - none：关闭fetch task优化
    - minimal：只在select *、使用分区列过滤、带有limit的语句上进行优化
    - more：在minimal的基础上更加强大了，select不仅仅可以是*，还可以单独选择几列，并且filter也不再局限于分区字段，同时支持虚拟列（别名）
+ 启用本地模式set hive.exec.mode.local.auto = true（默认为false），针对比较小的查询直接在本地处理所有任务

## 调整mapTask,reduceTask数量
+ 在执行查询时，map任务是根据文件分片得到的，有多少个分片就有多少个map任务，分片大小与如下三个参数有关，计算公式为：分片大小=max(mapred.min.split.size,min(dfs.block.size, mapred.max.split.size))
    - dfs.block.size: HDFS 上数据块的大小
    - mapred.min.split.size:最小分片大小
    - mapred.max.split.size:最大分片大小,新版本改为mapreduce.input.fileinputformat.split.maxsize
+ hive 默认使用 CombineHiveInputFormat 读取输入文件，其分片逻辑与hadoop略有差别，将小文件合并，减少了map数量，在通常情况下可以一定程度上提升效率，使用 set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;TextInputFormat 可以配置
+ 有很多情况需要增大或者减少map任务的数量，调整 mapreduce.input.fileinputformat.split.maxsize大小可以做到这一点，减小max可以增加map数，增大max可以减少map数。
+ hive.exec.reducers.bytes.per.reducer 可以设置reduce数量，如果不设置，hive会根据map阶段的输出自动推算reduce数量，可以配置hive.exec.reducers.bytes.per.reducer控制每个reducer处理的数据量来控制reduce数量

# 文件优化  
## 存储格式优化
+ hive支持多种存储格式，每种存储格式各有特点适用于不同的场景
    - textfile:Hive 默认文件存储方式，存储方式为行存储，数据不做压缩，优点是存储速度极快，格式简单，便于和其他工具共享数据。缺点是磁盘开销大，数据解析开销大，可以压缩，但是压缩以后数据不支持分片，查询效率最低。适合于小型查询，查看具体数据内容的和测试操
    - sequencefile:二进制存储格式，行式存储，优点是可压缩和切片，查询效率高。缺点是存储空间消耗最大,对于Hadoop生态系统之外的工具不适用。适用于数据量小，且查询字段比较多的场景（因为是基于行式存储），与其他存储格式相比并无明显优势，生产中一般不使用
    - orcfile:行列式存储，将数据按照行分块，每个块按照列存储，优点是压缩比高，自身支持切片，查询效率很高，缺点是存储效率低。适用于追求磁盘空间占用最小的场景，综合性能比较高，是业内主流选择之一
    - parquet:一种二进制存储格式，列式存储，优点是压缩比高，查询效率高，平台无关，缺点是存储效率低。综合性能与orc在伯仲之间，但是如果数据可能被其他框架访问，建议使用parquet，snappy配合parquet性能最高

## 小文件优化
+ 小文件产生原因如下:
    - 业务系统本身原因，在hdfs上存储了很多小文件
    - 使用分区表时使用动态分区，产生了很多小文件
    - reducer数量设置的太多
+ map端的小文件分为输入小文件和输出的小文件，针对输入的小文件，hive可以使用 CombineHiveInputFormat 进行小文件合并。针对输出的小文件通过hive.merge.mapfiles配置控制是否对输出进行合并，默认为true
+ reduce端的小文件主要是输出的小文件，使用 hive.merge.mapredfiles 配置项控制是否对输出文件进行合并，默认为false


# 查询优化
## 关键字选择
+ 列裁剪和分区裁剪，裁剪就是过滤不需要的数据，查询时需要哪一列的数据就只写哪一列，不要使用 select * ,可以减少中间表的存储开销。如果使用分区表和桶表，查询时先进行分区过滤
+ 避免直接使用order by ,会将所有的数据在一个reduce任务中进行全局排序，数据量很大的情况下性能很低。可以使用 distribute by 配合 sort by进行分区排序，distribute by会将数据按照指定标准分发到不同的reducer, sort by保证了每个reducer内部数据的顺序。如果取前N大，也可以使用这种方式先取出每个分类的前N大，然后将结果做一次全局排序
+ 使用group by条件过于单一时 ,很容易导致数据倾斜，根据28原则，大部分数据会集中在少部分key上。解决办法是：
    - group by 的条件更细化一些，先进行一次聚合，在进行二次聚合
    - 设置 hive.groupby.skewindata=true,hive会开启两个MR job
+ 使用left semi join 代替 in 和 exists 

## join优化
+ join时先过滤数据再进行连接，比如先过滤null值
+ join时小表join大表，因为join左边的数据会被加载到内存，如果有多个join，表的大小应该从左到右依次增大
+ 如果条件允许使用 left semi join 代替join,  left semi join  的查询结果只有左表数据，但是其中间表的数据会少很多
+ 利用mapjoin，mapjoin是将join中比较小的表直接加载到map任务的内存中，在map任务中进行join，充分利用分布式。但是必须保证内存可以承受小表的数据。
    - hive 会根据join表的大小，判断数据是否需要进行map join，当某个表的大小小于hive.mapjoin.smalltable.filesize 会从 Common Join 自动转为 map join

## 数据倾斜优化
+ 引起数据倾斜的原因及解决方式
    - 数据本身分布不均匀: 在程序设计初期尽量考虑到可能出现倾斜的数据，提前处理
    - 空值倾斜:某些值允许为空，可能导致计算的时候所有的空值最终被分配到同一个reduce，处理时提前过滤空值
    - 分组操作某些key数量很多: group by 很容易产生数据倾斜，可以开启局部聚合和两阶段聚合