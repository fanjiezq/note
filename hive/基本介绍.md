# 概念
+ hive 是一款建立在 map/reduce 框架之上的一个计算框架，它的作用就是让我们可以以sql的读写，管理，计算分布式存储系统上的文件。
+ hive 管理数据的原理是给数据建立一个逻辑映射，将文件映射为一张张表。因为大数据中最常见的文件是半结构化的文本文件，类似日志，每一行数据可以映射为表的一行数据。当然每行数据也可以分列，这就要我们根据数据的实际情况建立列的映射（以日志文件为例，每一行日志基本都包含 时间，日志级别，日志信息等，那么可以将这些同类型的信息看作一列，这就好像传统的数据库表）
+ hive 进行数据运算的原理是把sql脚本翻译成map/reduce程序,hive 本质上算是一个翻译引擎，它本身不保存任何数据，对于需要计算的数据会保存在hdfs上，对于数据和表的映射关系这类元数据，也保存在第三方数据库，比如mysql，hive唯一需要做的就是拿到数据和映射关系， sql脚本翻译成map/reduce程序，然后交给集群计算


# 表相关
## 表和文件
+ 创建表的前提是创建一个hive数据库，hive数据库和hive表在hdfs上都体现为一个文件夹

## 分区表和桶表
### 分区表
hive在查询数据时扫描整个目录，但是我们在查询时往往只关心其中一部分数据，此时可以用分区表来优化，普通表在hdfs上存储数据是直接存储在表目录下，而分区表会表目录下新建分区目录。创建表时指定分区依据partitionKey，插入数据时设定 partitionKey 的值，数据就会被保存在相应的分区目录下
    
    create table student_partition(id int,name string,sex string, age int,desc string) partitioned by (partitionKey string) row format delimited fields terminated by ',' stored as textfile;
### 桶表
桶表也是为了优化查询设计的表类型，在创建表时指定桶的数量，然后指定分桶的字段key，存储数据时hive会计算key的hash值，对桶数量取模决定数据保存在哪个分桶，类似mysql的垂直分表。与分区表不同的是，桶表的key必须是表中的字段，插入数据时也不需要携带额外的字段
    
    create table student_buckets(id int,name string,sex string, age int,desc string) clustered by (sex)  into 2 buckets row format delimited fields terminated by ',' stored as textfile;
## 内表和外表



# 优化
+ 数据存储优化
    1. 利用分区表和桶表减少查询时的数据扫描
+ 查询优化
    1. 查询的表是分区表或者桶表，尽量利用好两者特性，尽可能减少数据的扫描
    2. 尽量不要使用 order by 数据，因为会在reduce端进行数据的全量排序，如果必须进行全局排序，也应该在最终的结果上进行排序;如果取前N条数据，可以在map任务上限制查询数量N，最后在reduce任务排序取N
    3. 避免group by 产生的数据倾斜，group by语句产生的任务最终的数据聚合是在reduce任务中，相同的分组会被分配到同一reduce任务。根据2/8原则，某些分组的数据量会远超其他分组，使用set hive.groupby.skewindata=true，可以让hive调整生成计划，生成两个Job，第一个job会将数据均匀的分配到多个reduce任务进行聚合，第二个job再将聚合好的数据进行二次聚合
+ join优化
    1. 时先过滤数据再进行连接
    2. join时小表join大表，因为join左边的数据会被加载到内存，如果有多个join，表的大小应该从左到右依次增大
    3. 利用mapjoin，mapjoin是将join中比较小的表直接加载到map任务的内存中，在map任务中进行join，充分利用分布式。但是必须保证内存可以承受小表的数据
