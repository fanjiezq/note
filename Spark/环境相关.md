# standalone集群搭建
1. 创建3台服务器的，采用一主两从架构搭建，三台服务器主机名分别为 master, slave1 ,slave2
2. 每个服务器都需要安装并启动ssh服务，并互相开启无密码登录
3. 修改master的 /spark-2.1.1-bin-hadoop2.7/conf/slaves.template -> /spark-2.1.1-bin-hadoop2.7/conf/slaves  并将三台主机名写入文件，每行一个,内容如下

        master
        slave1
        slave2
4. 修改master的 /spark-2.1.1-bin-hadoop2.7/conf/spark-env.sh.template -> /spark-2.1.1-bin-hadoop2.7/conf/spark-env.sh  配置JAVA_HOME和主节点ip和通信端口号，内容如下
        
        export JAVA_HOME=/usr/local/include/jdk1.8.0_191
        SPARK_MASTER_HOST=master
        SPARK_MASTER_PORT=7077
5. 将master节点的整个spark目录同步到两个从节点 /spark-2.1.1-bin-hadoop2.7 
6. 在master节点的执行 /usr/local/include/spark-2.1.1-bin-hadoop2.7/sbin/start-all.sh 启动集群
7. 在浏览器访问 http://master:8080，检查集群

