# 架构
+ zookeeper 集群采用主从模式，由三个组件构成
    - Master:负责发起投票和决议，更新系统状态
    - follwer:负责接收客户端的读写请求，在处理写请求是保证过半写入机制;在节点选举时进行投票
    - obServer:与follwer一样负责接收客户端的读写请求，但是不参与过半机制，也不参与节点选举投票，可以在不影响写性能的情况下提升集群读性能

# 一致性实现原理
## 数据请求流程
1. 客户端可以连接集群任意一个节点，发起一个写请求，无论客户端连接到谁，这个写请求最终都会被转发到leader节点进行写入投票
2. 数据写入过程类似事务的两阶段模型，leader 接收到写请求后会广播到所有follwer节点进行数据写入准备，到提交的前一步，然后所有follwer返回准备结果，如果有超过一半的follwer写入成功(包括leader)，则表示数据写入成功，leader本身commit,并且对所有learner进行广播commit,此时的广播包含follwer和obServer，因为obServer之前并没有这个事务的信息，所以针对obServer的提交还要包含提交的最新数据。最后将结果返回给客户端连接的learner，进而返回给客户端

## leader崩溃时保证已经在leader提交的数据同步到整个集群
+ 如果在follwer过半写入成功，且leader已经将本地数据提交了，但是在向follwer进行广播commit时leader崩溃，那么follwer的数据虽然已经是最新的，但是并没有提交，zk需要保证在leader提交的数据，在整个集群都提交
+ zk使用ZXID解决以上问题，ZXID是zk的事务编号，leader每次写操作都会开启一个事务并设置一个事务编号，当前事务的编号是之前事务编号+1,ZXID被保存在每个节点本地。因为ZXID自增的特性，可以得出，一个节点的ZXID最大，它必然包含了集群最新的数据，所以在进行节点选举时就选ZXID最大的节点作为新节点，就可以保证在旧leader提交的数据，在新的leader也有。新leader选举完成后，learner从新leader同步数据，集群状态就可以和错误恢复之前一样

