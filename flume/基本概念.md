# 简介
+ flume 是一种高可用，分布式海量日志处理系统，负责日志的采集，聚合，传输。主要解决大数据处理流程中的数据传输问题
+ flume 的价值是简化到多个系统海量日志的采集和传输，它提供了很简单多样的方式对日志进行采集和传输，生产环境中一般用于将多个系统的日志实时传输到hdfs或者kafka，甚至直接传输到spark等实时计算框架

# 基本架构
+ flume 作为大数据处理流程中的一个中间件，是一种常驻进程，每个flume 启动以后就会根据用户配置的规则对日志进行采集和传输
+ flume 采用生产者消费者模式构建起整个体系，整个flume由三个基本组件构成，生产者-> 缓冲区 -> 消费者，分别对应三个基本组件 source -> channel -> sink。source采集到数据后进行封装然后传递到channel，然后由sink消费，可能存储到存储设备，也可能传输到下一个source继续进行处理

# 核心组件
+ event:flume中的数据抽象。在flume中，所有的数据都会被封装成为一个个event，比如一个行日志就可以被封装成为一个event。每个event油hesder和body两部分组成，body一般就是采集到的一行日志数据，header中以key:value形式存储的各种属性，用于后续流程的分类和处理
+ source:flume数据源的抽象。生产环境中日志数据来源可能多种多样，可以是日志文件，可以是网络数据，甚至来源于数据库，针对不同的数据源，数据的采集方式肯定也是不一样的，为了屏蔽这种差异，flume提供了一个source的抽象，数据源可以多种多样，但是最终都会形成source并将数据封装成为event
+ channel:数据的缓冲区。为了降低系统耦合性，source采集到数据后会先存放到一个缓冲区，由消费者去拉取数据进行消费。针对不同的场景，channel也提供多种类型供选择，基于内存的，基于磁盘的，基于kafka的，根据业务场景选择不同类型的channel
+ sink:数据的消费者的抽象。在生产中，日志数据采集完成后可能进行多种处理，或者直接存储到文件系统，也可能需要继续进行处理。为了屏蔽差异，flume提供 sink 的抽象，无论下游对接的是什么系统，都是sink
+ agent:agent是一个整体的概念(agent = source + channel + sink)，每个agent都是一个flume进程

# 基本用法
1. 下载 flume 后解压得到flume程序
2. 创建一个 agent 配置文件，启动agent。如下为一个简单的agent配置文件(example.conf)，用于从网络中采集数据(source=netcat)，将结果打印到控制台(sink=logger)
    
        # Name the components on this agent
        a1.sources = r1
        a1.sinks = k1
        a1.channels = c1

        # Describe/configure the source
        a1.sources.r1.type = netcat
        a1.sources.r1.bind = localhost
        a1.sources.r1.port = 44444

        # Describe the sink
        a1.sinks.k1.type = logger

        # Use a channel which buffers events in memory
        a1.channels.c1.type = memory
        a1.channels.c1.capacity = 1000
        a1.channels.c1.transactionCapacity = 100

        # Bind the source and sink to the channel
        a1.sources.r1.channels = c1
        a1.sinks.k1.channel = c1

3. 启动agent实例。
        
        $ bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console

# 高级用法
## 数据处理内部机制
在最简单的情况下，source，channel，sink 三者一条线，但是生产环境中，情况通常很复杂，通常有如下三种形式
+ 多代理流程:日志需要经过多层处理，就需要多个agent连接起来形成一条链
+ 流合并:同一个agent对接多个数据源，需要进行数据的合并
+ 流分发:日志需要根据某些规则进行分类，并且传输到不同的sink
在最粗粒度的概念里，flume只包含了 source，channel，sink 三个组件，实际上更深入的看，其内部还存在两个组件(Channel Selectors | Sink Processors ) 和 一个事务机制 来完成复杂的数据处理。数据被source 采集并封装成为event，这些event并不是直接发送到channel，而是先被 Channel Selectors 进行选择，由它决定数据应该如何分配和转发。Sink也不是直接从channel拉取数据，而是依赖 SinkProcessor 采取一定策略。且无论是从 source 到 channel 还是 channel 到 sink 。两个步骤都存在事务机制。

## Channel Selectors
每个source可以对接多个channel，其中数据也可以使用不同的策略进行分发。flume 有三种分发策略
+ replicating:复制选择器，selector将所有event 转发到所有对接的channel，这也是默认的分发策略
+ multiplexing:多路复用选择器，selector 根据event头部的属性，将event转发到不同的channel
+ customer:自定义选择器，用户自己编写选择器，根据业务需要决定数据如何转发

## Sink Processors
每个channel 可以对接多个sink，但是每个sink只能对接一个channel。在实际使用中，如果channel对接了多个sink，就会出现故障转移或者负载均衡的需求。flume提供 Sink Processors 组件解决这种需求。其原理是将多个sink分成一个组，然后Sink Processors对这个组进行一定的选择策略。flume存在以下三种组策略:
+ failover: 故障转移。channel下游对接多个sink，这些sink以主从形式存在，Sink Processors 会将数据发送到主节点，一旦主节点宕机，数据立即发送到从节点
+ load_balance:负载均衡。channel下游对接多个sink，Sink Processors会根据一定策略将数据均匀分发到每一个sink
+ customer:自定义Sink Processors，用户自己编写处理器，根据业务需要决定数据如何转发

