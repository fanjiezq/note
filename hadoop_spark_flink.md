# 并行度
三个框架都是分布式计算框架， 核心思想都是分而治之，用并行计算提升计算的整体效率，但是三者在实现并行度策略上有所不同
## hadoop
+ mapreduce的核心功能是海量的数据计算，因为其处理的数据量巨大，所以必须限制每个任务的数据量，不能让一个map任务处理过多的数据，否则无法充分发挥分布式计算的能力，拉长计算时间，所以hadoop分区基于数据
+ mapreduce的并行读依靠文件切片，如果文件比较小，一个文件就是一个切片，如果文件比较大，一个切片一般为一个文件块，每个切片对应一个map任务

## Spark
+ spark的job是分阶段的，且阶段之间存在顺序依赖，所以每个阶段都类似与一次mapreduce,可以使用集群的几乎所有计算资源，如何让这些计算资源充分利用提升效率是spark考虑的核心，所以spark的每个阶段都可以设置并行度，一般设置为可使用资源的cpu核心数，可以最大程度利用资源
+ spark的第一个阶段是直接对接数据源，无法设置并行度，它根据数据源的不同实现不同的并行度，如果数据源是HDFS的话，并行度就按照hdfs的标准，等于处理的文件块数;如果是本地文件，

## flink
+ Flink程序一般使用各种算子将数据进行一系列的转换和分发，在实际运行过程中，每个算子一般对应一个任务，而这些任务又可以被分为若干子任务，子任务的数量就是这个任务的并行度，每个算子的并行度都是可以设置的
+ 任务与任务之间存在依赖关系，上游任务处理完成数据以后，会立即将数据传递到下游，而且数据的传递并不需要等待。flink不同任务之间的并行度是各不相关的，每个任务都可以设置不同的并行度，那么就存在一个数据分配方式的问题
+ flink的任务之间数据传递分为两种:
    - 一对一模式:两个任务的并行度相同，且不存在需要重新分发数据的算子，则上游算子的每个子任务与下游算子的每个子任务一一对应，数据的传递也是一一对应
    - 重新分发模式:上下游两个任务的并行度不同，或者因为某些算子需要将数据按照一定规则分配(keyBy)，则上游算子的数据需要被打乱分发到下游算子的各个子任务
+ flink的每个子任务运行都需要一个slot,父任务相同的子任务不能运行在同一个slot,但是父任务不同的子任务可以共享slot，所以想要运行一个flinl程序，集群slot数量等于算子的最大并行度即可


# 数据倾斜
## 产生位置
+ hadoop 的数据倾斜只会发生在shuffle阶段，存在多个分区的时候大量数据被分在少量分区，导致少量reducer处理大量数据，任务总体时间被少量任务拉长
+ spark 的数据倾斜也是只发生在shuffle阶段，存在reduceByKey， groupByKey，join等触发shuffle算子的位置
+ flink 的数据倾斜一般出现在两个位置，数据源（比如kafka的分区数据本身倾斜），keyBy等分流的算子
## 解决办法
数据倾斜的解决办法思想大致相似， 最根本的思想就是让数据均匀分布，从解决的源头分可以分为两类 1）在数据源解决 2）在数据处理过程中解决 ；从实现方式也可以分为两类 1）针对key解决 2）针对计算流程解决
+ 从数据源头解决数据倾斜
    - hadoop和spark一般对接hdfs或者hive，如果数据本身倾斜，部分类型数据很多，部分很少，那么可以尝试对数据进行预处理，提前聚合，或者在程序录入数据时聚合（这是最理想的情况），这种方式保证了数据处理时不存在倾斜的情况，但是其本质只是把对倾斜数据的处理提前了，并没有根本的性的解决
+ 在数据处理过程中解决数据倾斜
    - 因为数据倾斜的场景很多，比如聚合操作某几个key数据很多，大量的key数据很多，join操作某几个key数量很多。不同的场景解决方式不通，但是都属于在数据处理过程中解决数据倾斜，具体见下文
+ 针对key解决数据倾斜
+ 针对计算流程解决数据倾斜



