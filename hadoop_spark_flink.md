# 作业调度
+ hadoop严格按照map/reduce模式，在map阶段将数据切分成片封装成mapTask，然后分发给集群node运行，然后根据业务需求启动若干ReduceTask完成计算输出结果；在map/reduce过程中，必然经过Shuffle阶段，特别是存在多个ReduceTask的情况下，Shuffle阶段将数据数据经过分区，排序，局部合并，保证数据能正确高效的进入ReduseTask
+ Spark将运行流程划分为多个stage,每个stage又分为多个task在集群中的多个node运行，每个stage的运算结果交给下一个stage继续处理。可以看出Spark的运行流程其实就是多个map/reduce连接起来的，除了第一个和最后一个stage,其他的stage即是map任务也是reduce任务。 这种将多个map/reduce阶段连接成逻辑链的方式让数据处理更灵活了，可以非常简单的在一个程序中编写多个map/reduce逻辑。
+ flink的任务调度依赖 ExecutionGraph，在程序运行初期根据算子的关系构建出运行图，然后启动相应的TaskManager执行运算，可以说在ExecutionGraph构建完成后每个元素的数据流路径已经确定，每个元素会经过固定的数据流路线到经过各个TaskManager执行算子的运算

# 高可用
+ hadoop的高可用分为hdfs 和 yarn 两者的高可用
    hdfs: 可以实现多个namenode,一主多从
    yarn: 可以实现多个resourcemannager,一主多从
+ spark只是一个计算框架，一般直接运行在yarn集群，所以本身不需要考虑部署的高可用。在计算过程中Driver 就是Yarn的AM，Yarn会保证它的失败重试
+ flink 的高可用主要是解决jobmanager单点故障，无论哪种集群，flink的jobmanager默认都是单点的，flink可以使用zookeeper实现jobmanager的高可用，以主从模式创建多个jobmanager


# 集群类型和作业部署模式
+ spark:
    - Local:单机运行，不需要启动spark集群，用单机的多个线程来模拟Spark分布式计算，适用于本地测试。作业提交以后只有SparkSubmit进程，它即负责driver角色的任务提交，监控，又负责executor角色的计算
    - Standalone模式: 构建一个master + worker 集群，优点是集群构建很简单，缺点是集群集群只能服务于spark，不能共享给其他框架，资源调度策略比较单一。
        - client模式提交(--deploy-mode cluster):此模式master作为集群资源管理者，SparkSubmit进程即是客户端也是driver,作业执行过程中，driver必须像master申请资源，作业完成前，SparkSubmit进程不会退出
        - cluster模式提交(--deploy-mode cluster):此模式master作为集群资源管理者，SparkSubmit进程作为客户端，只负责提交任务，完成后立即推出，由 DriverWrapper 进程运行Driver,进行资源的申请和监控
    - Spark on Yarn模式:Spark客户端直接连接Yarn，和其他框架共享集群资源。
        - client模式提交: 客户端新建一个SparkSubmit进程，将作业提交到集群，并运行driver程序，负责监控程序，此进程会一直存在；集群中的某个node会启动ExecutorLauncher进程，来做为ApplicationMaster申请资源
        - cluster模式提交: 客户端新建一个SparkSubmit进程，将作业提交到集群，起作用仅仅是作为客户端把作业提交到集群，完成后立即关闭; 集群某个node会启动一个Container运行Driver程序，Driver就相当与一个AM
+ flink:
    - Local:单机运行，不需要启动集群，用单机的多个线程来模拟分布式计算，适用于本地测试。作业提交后只有一个主进程运行负责计算
    - Standalone模式: 构建一个 Cluster + TaskManager 集群，Cluster作为集群资源管理者。优点是集群构建很简单，缺点是集群集群只能服务于flink，不能共享给其他框架，资源调度策略比较单一。
    - Flink on Yarn模式:Flink客户端直接连接Yarn，和其他框架共享集群资源。
        - Session Mode：事先在yarn集群上启动一个flink集群，所有作业都通过client提交到这个集群运行，共享集群资源。好处是节省了集群启动的开销，坏处是资源完全不隔离，某个任务导致一个TaskManager失败，其上运行的所有任务都会失败
        - Application Mode: 一个作业启动一个集群，集群是作业提交以后临时建立的，作业完成后销毁集群回收资源。好处是可以与其他框架共享yarn这种资源管理器，资源的隔离性也比较好，一个作业引起的问题只会影响本作业，缺点是集群启动销毁的开销比较大
        - Per-Job Mode:集群的建立方式与 Application Mode 一样，只是资源隔离性更强，因为一个  Application 可能存在多个Job，Per-Job Mode为每个Job都启动一个集群，优点是资源隔离性极强，缺点是集群启动销毁的开销比较大

# shuffle过程
+ hadoop的shuffle阶段比较复杂，包含了数据的分组，排序，局部合并，其流程固定，是map/reduce最主要的性能优化点
+ spark在stage之间存在shuffle,从高维度上看此阶段和hadoop一样，但是其底层的实现方式不同，spark的shuffle更多的是确定上游的数据该如何分发到下游，没有排序，后来也默认排序但是只是为了底层性能优化在map端排序，reduce端并无排序效果，排序还是依靠算子自行实现
+ flink没有shuffle概念，取而代之的是partitioning，即上游元素如何分发到下游，与spark的不同点在于，spark上游数据所有的数据准备好以后才可以分发到下游，有一个阻塞的过程，flink则是一个元素一个元素的处理，所以它不需要复杂混洗流程，只需要一个分发策略

# 并行度
三个框架都是分布式计算框架， 核心思想都是分而治之，用并行计算提升计算的整体效率，但是三者在实现并行度策略上有所不同
## hadoop
+ mapreduce的核心功能是海量的数据计算，因为其处理的数据量巨大，所以必须限制每个任务的数据量，不能让一个map任务处理过多的数据，否则无法充分发挥分布式计算的能力，拉长计算时间，所以hadoop分区基于数据
+ mapreduce的并行读依靠文件切片，如果文件比较小，一个文件就是一个切片，如果文件比较大，一个切片一般为一个文件块，每个切片对应一个map任务

## Spark
+ spark的job是分阶段的，且阶段之间存在顺序依赖，所以每个阶段都类似与一次mapreduce,可以使用集群的几乎所有计算资源，如何让这些计算资源充分利用提升效率是spark考虑的核心，最好是每个Stage都能利用上集群全部资源。
+ spark程序的并行度与两个因素有关，一个是设置的并行度，一个是数据的分区数量。并行度控制Stage的Task数量，分区数量是对数据进行分区，两者结合决定作业的并行度。所以首先需要设置作业的并行度，这样首个Stage的Task数量是确认的，后续算子会根据之前算子的数据分区调整并行度。可以使用groupByKey，coalesce,repartition等算子重新分区实现并行度的调整
+ spark的第一个阶段是直接对接数据源，不同数据源使用不同的方式进行数据分区，如果数据源是HDFS的话，并行度就按照hdfs的标准，等于处理的文件块数;普通文件和集合就直接在代码中指定分区数量

## flink
+ Flink程序一般使用各种算子将数据进行一系列的转换和分发，在实际运行过程中，每个算子一般对应一个任务，而这些任务又可以被分为若干子任务，子任务的数量就是这个任务的并行度，每个算子的并行度都是可以设置的
+ 任务与任务之间存在依赖关系，上游任务处理完成数据以后，会立即将数据传递到下游，而且数据的传递并不需要等待。flink不同任务之间的并行度是各不相关的，每个任务都可以设置不同的并行度，那么就存在一个数据分配方式的问题
+ flink的任务之间数据传递分为两种:
    - 一对一模式:两个任务的并行度相同，且不存在需要重新分发数据的算子，则上游算子的每个子任务与下游算子的每个子任务一一对应，数据的传递也是一一对应
    - 重新分发模式:上下游两个任务的并行度不同，或者因为某些算子需要将数据按照一定规则分配(keyBy)，则上游算子的数据需要被打乱分发到下游算子的各个子任务
+ flink的每个子任务运行都需要一个slot,父任务相同的子任务不能运行在同一个slot,但是父任务不同的子任务可以共享slot，所以想要运行一个flinl程序，集群slot数量等于算子的最大并行度即可

# 数据倾斜
## 产生位置
+ hadoop 的数据倾斜只会发生在shuffle阶段，存在多个分区的时候大量数据被分在少量分区，导致少量reducer处理大量数据，任务总体时间被少量任务拉长
+ spark 的数据倾斜也是只发生在shuffle阶段，存在reduceByKey， groupByKey，join等触发shuffle算子的位置
+ flink 的数据倾斜一般出现在两个位置，数据源（比如kafka的分区数据本身倾斜），keyBy等分流的算子
## 解决办法
数据倾斜的解决办法思想大致相似， 最根本的思想就是让数据均匀分布，从解决的源头分可以分为两类 1）在数据源解决 2）在数据处理过程中解决 ；从实现方式也可以分为两类 1）针对key解决 2）针对计算流程解决
+ 从数据源头解决数据倾斜
    - hadoop和spark一般对接hdfs或者hive，如果数据本身倾斜，部分类型数据很多，部分很少，那么可以尝试对数据进行预处理，提前聚合，或者在程序录入数据时聚合（这是最理想的情况），这种方式保证了数据处理时不存在倾斜的情况，但是其本质只是把对倾斜数据的处理提前了，并没有根本的性的解决
+ 在数据处理过程中解决数据倾斜
    - 因为数据倾斜的场景很多，比如聚合操作某几个key数据很多，大量的key数据很多，join操作某几个key数量很多。不同的场景解决方式不同，但是都属于在数据处理过程中解决数据倾斜，具体见下文
+ 针对key解决数据倾斜
    - 如果进行聚合或者join操作发现只有非常少量的key的数据量远高于平均值，可以先过滤这几个key，然后单独提取出这几个key进行处理
    - 如果进行聚合操作，且有很多key的数据量远高于平均值，可以使用两阶段聚合，首先将key加上不同前缀，分批聚合，然后第二阶段去除前缀，全量聚合
+ 针对计算流程解决数据倾斜
    - 针对join操作，且两个数据集一大一小，小的足以存储在内存中，考虑使用map端join，将小的数据集放在mapper的内存，将大数据集拆分
    - 如果join操作的两个数据集都很大，且有很多key的数据量远高于平均值，采用类似两阶段聚合，将把key加上不同的后缀进行局部连接，然后去除后缀进行全局连接

# 流处理(spark vs flink）
## 模型对比
+ Spark的DStream是微批的方式模拟流，其本质依旧是批处理，就是将一个个小的时间间隔的数据封装成一个个RDD计算;Structd Stream则是将数据看作一个无边界的表，每到来一个数据表就新增一行，比起DStream这种模型操作更灵活，可以使用SQL的API，而且抛弃了微批的概念，数据可以做到更低的延迟
+ Flink是真正的基于流思想，每来一个数据就处理一个数据，计算没有延迟，可以达到真正的实时计算

## 窗口类型
窗口是为了处理无界的流创建出来的概念，其本质就是一个数据集，一般是时间窗口但也不是必须以时间维度建立窗口，也可以以元素的数量为维度。
+ DStream的窗口就是多个微批，把多个采集周期的数据看作一个数据集合就是一个窗口，因为采集周期的时间是固定且完整不可切分的，所以DStream窗口大小必须是采集周期的整数倍
+ Structd Stream 的时间窗口是基于事件时间的，没有采集周期的限制，指定起来更灵活，可以随意指定窗口大小，非常灵活。而且在Structd Stream认为时间窗口本质就是根据时间这一属性为维度进行聚合操作，时间与其他属性并无区别，所以所有的窗口计算都是一个聚合操作，只是把时间属性作为聚合key
+ flink包含两种窗口，TimeWindow 和 CountWindow，其TimeWindow 的时间语义更丰富，包含 到达时间，处理时间，事件时间，可以根据业务需要指定需要那种时间类型。与Structd Stream不同，时间在flink中地位超然，并不与聚合算子合并，所以每个窗口之后必定跟随一个聚合算子。

## 触发器
+ 触发器就是出发一个窗口执行计算的条件，DStream没有触发器概念，因为它是自动计算的，时间周期一到立即计算
+ Structd Stream 包含四种触发器
    - 动态微批:默认触发器，采用微批模式，计算引擎会尽可能快的采集数据并处理，数据来的比较慢的时候每个元素都会触发一次计算。每一个批处理都在上一次计算结束以后开始
    - 固定微批:指定批处理时间，计算引擎会按照指定的时间进行数据采集并计算，如果上一批的数据在一个时间周期内计算完成，数据引擎也会等待上一周期结束才开始下一周期;如果上一周期计算没有完成，下一周期会等待上一周期完成才开始;如果没有新数据可用，则不会启动微批处理
    - 一次性批处理:仅执行一个微批处理来处理所有可用数据，然后自行停止。适用于一次性作业
    - 连续处理:利用checkpoint机制记录查询状态，可以实现低至1ms的延迟，几乎达到实时计算
+ flink的的触发器比较灵活，可以根据元素触发，根据处理时间触发，根据事件时间触发。默认是根据事件时间触发，元素的时间事件到达时间窗口的结束时间立即触发计算

## 针对迟到数据
+ Structed Stream 依靠 Watermark 机制处理迟到的事件，为事件戳属性绑定一个延迟事件作为watermark，窗口 以 watermark 作为触发计算和关闭窗口的标准，而不是以事件时间作为标准
+ Flink 提供三种机制处理迟到数据
    - WaterMark:与 spark 的 Watermark一样 
    - allowedLateness:为窗口设置一个延迟关闭的时间，为处理那些在窗口正常关闭事件之后一小段时间到来的数据。这类数据每来一个都会触发一次窗口计算
    - sideOutputLateData:为窗口设置一个旁路输出，保存那些在窗口关闭以后到来的数据，后续手动处理

## 状态机制
+ spark提供了一个 mapGroupsWithState 算子用于保存状态，在 流处理过程中可以实现状态的获取和更新，但是此函数必须跟随在groupByKey算子后面
+ flink 提供 RichFunction 接口，实现此接口就可以创建状态变量，并进行访问和更新，所以每个算子内部都可以获取状态。flink提供了五种状态变量(ValueState，ListState，ReducingState，AggregatingState，MapState)可以根据业务场景选择使用。

## 持久化机制和故障恢复
+ 数据持久化有两个作用，一是当程序中有需要复用的计算结果，将其持久化到内存中，达到数据的复用;二是将计算结果和状态持久化到分布式的存储系统，程序进行异常恢复时可以从失败处恢复，不需要重新计算。
    - 针对数据复用,DStream 采用RDD的持久化机制，调用 persist() 就可以将流计算的数据持久化到内存，达到数据复用;对于基于窗口的操作比如reduceByWindow、reduceByKeyAndWindow，以及基于状态的操作，比如updateStateByKey，默认就隐式开启了持久化机制，不需要显示调用persist()方法。
    - 针对异常恢复，Dstream利用checkpoint机制，将计算的元数据和数据保存在外部存储系统，程序异常恢复时从外部存储系统还原计算状态。使用了有状态的transformation操作——比如updateStateByKey，或者reduceByKeyAndWindow操作都需要checkpoint，所以使用这些算子都需要指定一个外部存储路径。使用时指定一个目录和一个触发周期，计算引擎会自动的周期性进行持久化。
    - 异常恢复分为两种，一种是对数据的异常恢复，当程序启动后计算引擎会自动从持久化目录获取数据恢复，不需要额外处理；对元数据的恢复，比如计算流程，则需要修改程序，从checkpoint目录读取数据，根据数据得到一个Context
+ Structd Stream 的持久化机制和异常恢复机制和DStream一样
+ Flink 也有两种持久化方案，但是在概念上与Spark关注的点不同，概念上也有所差别
    - CheckPoint:CheckPoint是flink程序的快照，此快照包含了算子的状态和数据的偏移量，主要用于异常恢复
    - SavePoint:SavePoint也是系统的快照，其使用和原理和CheckPoint一致，只是CheckPoint的数据在程序不需要时自动删除， SavePoint则永久保存，除非用户手动删除，SavePoint主要用于系统升级
    - Flink可以指定持久化数据的存储位置，可以是内存，文件系统，RocksDB
    - 相比于Spark,flink没有针对数据复用的持久化策略，因为flink是每来一个元素就处理一个元素，不会存在大量的数据处理结果需要缓存，所以没有必要

## 性能调优
+ 性能调优的方式很多，要结合具体的业务场景分析，但是一般都是针对以下四点优化
    - 资源的充分和高效利用。可以申请多少资源，如何分配
    - 并发调优。数据如何分区，最大化利用框架的并发特性
    - Shuffle调优。如何避免shuffle，不可避免时采用哪种shuffle
    - 解决数据倾斜问题

# exactly-once 的保证
+ Spark Stream: 严格来说Spark Stream并没有提供exactly-once的语义保证，更多的是依靠source，sink以及特殊编码实现，一般将kafka作为source，依靠kafka的offset实现exactly-once，sink也需要特殊的编码方式比如幂等写入，事务写入，手动提交ack等方式实现exactly-once 
+ Flink:
    - 幂等写实现:幂等写就是保证任意多次向sink写入同一条数据，只有一条生效，通常使用hbase.redis作为sink实现幂等写，但是使用场景有限
    - checkpoint + 两阶段提交: flink将数据暂存起来，等到checkpoint完成后才提交到sink,只有经过checkpoint确认后的数据才会被下发到sink,这部分数据可以使用两阶段提交的方式实现事务性写入，但是要sink支持事务
    - checkpoint + 预写日志: flink将数据暂存起来，等到checkpoint完成后才提交到sink

# 背压处理
背压机制是所有流处理系统都必须要考虑的能力，因为生产环境数据流的到来速度是不一样的，如果上游数据生产速度过快，下游来不及消化，就会导致下游出现资源不足或者内存溢出，如何保证系统在波动比较大的情况下仍旧能够平稳运行是背压机制需要考虑的问题。而且背压机制必须从数据源头到数据结束整个覆盖才有意义
+ spark背压机制:
    - spark1.5 之前采用静态速率预估实现背压，预估Executor的消费速度，在程序中预先设置一个发送速率值，各个Executor遵循这个速率发送和接受数据
    - spark1.5 之后采用动态速率预估实现背压，Driver内部存在一个RateController监控各个executor的消费速度，然后进行速率预估，并将估值发送给各个Executor，控制生产和消费速度
+ flink背压机制:
    - flink1.5 之前flink采用缓存池 + 阻塞的机制实现背压，flink的TaskManager的发送端和接受端都存在缓冲池，接受端缓存满了以后就不会从发送方拉取数据，导致发送方缓存池数据积压，发送缓存满了以后也会拒绝接收数据，这样层层递进，整个计算链条实现背压.此方案的问题是一个节点处理速度慢会影响整个计算链条
    - flink 1.5 之后将缓存分为两部分，独占缓存和浮动缓存，消费端会把独占缓存大小发给发送端，发送端先尽可能快的发送数据直到独占缓存变为0,同时发送方会把在排队的数据量发送给接收方，接收方根据自己的情况决定要不要使用浮动缓存。这样消费快的时候不开启浮动缓存，消费慢的时候开启浮动缓存，让上游能继续发送数据不至于导致整个计算链条被阻塞。


# 内存管理
+ spark的内存管理主要就是针对Executor的JVM Heap内存划分，主要包含三个部分(基于spark 2.x)
    - Reserved Memory:保留内存，固定300M
    - Spark Memeory:框架运行需要的内存，包含Storage Memeory 和 Execution Memory，分别用于数据的持久化和shuffle算子产生的结果，默认占用空间 (Heap Size - 300MB) x 75% 
    - User Memory:用户内存，用于保存我们编写程序时使用的变量，默认占用空间 (Java Heap - Reserved Memory) x 25% ，所以有时候我们的变量数据并没有超过Executor总内存也会出现OOM,因为超过了User Memory
+ Flink采用 MemorySegment 方式管理 TaskManager 的内存，MemorySegment一段固定长度的内存，默认32KB，是flink内存管理的基本单元。MemorySegment 可以是堆内内存，也可以是堆外内存，可以说Flink在JVM内存管理体系之上新创建了一套体系，更像存C++的内存管理体系
    - NetWork Buffer:用于网络传输的缓存，在TaskManagerer启动时分配的
    - Managed Memeory: 由 MemoryManager 管理的一组 MemorySegment 集合，主要用于框架的cache，join等中间数据的存储
    - Remaining JVM heap:保存TaskManager的数据结构，和用户代码的局部变量